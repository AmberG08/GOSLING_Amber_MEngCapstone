{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmberG08/GOSLING_Amber_MEngCapstone/blob/master/vcc_lstm_gru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/mnt')\n",
        "#nb_path = '/content/notebooks'\n",
        "#os.symlink('/content/mnt/My Drive/Capstone', nb_path)\n",
        "##sys.path.insert(0, nb_path)  # or append(nb_path)\n",
        "\n",
        "!pip install scikeras[tensorflow]\n",
        "!pip install mapie"
      ],
      "metadata": {
        "id": "qgQ38qQyVzaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OZoUcpOlXh1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, InputLayer, GRU\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from mapie.regression import MapieRegressor\n",
        "\n",
        "'''Load in file'''\n",
        "df_main = pd.read_csv('/content/drive/MyDrive/Capstone/CleanedData.csv')\n",
        "\n",
        "'''Load in file'''\n",
        "df_main = pd.read_csv('/content/drive/MyDrive/Capstone/CleanedData.csv')\n",
        "df_main['Timestamp'] = pd.to_datetime(df_main['Timestamp'], format='%d/%m/%Y %H:%M')\n",
        "\n",
        "\n",
        "'''Getting VCC datapoints'''\n",
        "df_celldata = pd.DataFrame(df_main, columns=['Timestamp', 'VCC'])\n",
        "\n",
        "no_nans = df_celldata[~df_celldata.isnull().any(axis=1)]\n",
        "print(no_nans)\n",
        "\n",
        "\n",
        "actuals = df_celldata['VCC']\n",
        "\n",
        "celldata=df_celldata['VCC'].to_numpy()\n",
        "celldata = celldata.reshape((len(celldata),1))\n",
        "\n",
        "boxcox = PowerTransformer(method='box-cox')\n",
        "df_celldata['VCC'] = boxcox.fit_transform(celldata)\n",
        "\n",
        "'''Separating data'''\n",
        "time_sep=pd.to_datetime('2021-05-04 9:35:00')\n",
        "df_log = df_celldata[df_celldata['Timestamp'] <= time_sep]\n",
        "df_death = df_celldata[df_celldata['Timestamp'] >= time_sep]\n",
        "\n",
        "df_log = df_log['VCC']\n",
        "df_death = df_death['VCC']\n",
        "\n",
        "nan_indices_log = np.isnan(df_log)\n",
        "coefficients_log = np.polyfit(df_log.index[~nan_indices_log], df_log[~nan_indices_log], 3)\n",
        "df_log= np.polyval(coefficients_log, df_log.index)\n",
        "#print(df_log.shape)\n",
        "\n",
        "nan_indices_death = np.isnan(df_death)\n",
        "coefficients_death = np.polyfit(df_death.index[~nan_indices_death], df_death[~nan_indices_death], 1)\n",
        "df_death = np.polyval(coefficients_death, df_death.index)\n",
        "#print(df_death.shape)\n",
        "\n",
        "'''Inverse box cox transform'''\n",
        "\n",
        "\"\"\" Concatenation \"\"\"\n",
        "df_log = df_log[:-1] # cut out last datapoint to make them connect\n",
        "df_main['VCC'] = boxcox.inverse_transform(pd.concat([pd.DataFrame(df_log), pd.DataFrame(df_death)], axis=0, ignore_index=True))\n",
        "\n",
        "plt.plot(df_main.index, df_main['VCC'], label='Boxcox polyval', color='black')\n",
        "plt.scatter(actuals.index, actuals, label='Boxcox transformed Data', color='black')\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Box cox VCC\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "'''Cut out intial data''' ##Cut out as required\n",
        "cut_date_time = pd.to_datetime('2021-04-30 14:45:00')\n",
        "df_main = df_main[df_main['Timestamp'] >= cut_date_time]\n",
        "actuals = df_main['VCC']\n",
        "\n",
        "# plt.plot(df_main.index, df_main['VCC'], label='Boxcox polyval', color='black')\n",
        "# #plt.scatter(df_celldata.index, df_celldata['VCC'], label='Boxcox transformed Data', color='black' )\n",
        "# plt.xlabel(\"Index\")\n",
        "# plt.ylabel(\"Box cox VCC\")\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "IjyP-dL0-_oy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8jDvaXFVe34"
      },
      "outputs": [],
      "source": [
        "\"\"\" Set features and target \"\"\"\n",
        "filtered_df= df_main.drop('Timestamp', axis=1)\n",
        "X_df = filtered_df[['Pred (X) 3 PV - O2 Sparge','CEDEX - GLC3B', 'Added Volume', 'Total Volume', 'VCC']]\n",
        "y_df = filtered_df[['VCC']]\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "X_scaler = MinMaxScaler(feature_range=(0,1)).fit(X_df)\n",
        "y_scaler = MinMaxScaler(feature_range=(0,1)).fit(y_df)\n",
        "\n",
        "X_df = X_scaler.fit_transform(X_df)\n",
        "y_df = y_scaler.fit_transform(y_df)\n",
        "\n",
        "def df_to_X_y(df, window_size):\n",
        "  df_as_np = df #df.to_numpy()\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(len(df_as_np)-window_size):\n",
        "    row = [r for r in df_as_np[i:i+window_size, [0, 1, 2, 3, 4]]]#, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]] #[a] wraps the row in brackets\n",
        "    X.append(row)\n",
        "    label = df_as_np[i+window_size][4]\n",
        "    y.append(label)\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "print('Windowing Function in progress')\n",
        "\n",
        "WINDOW_SIZE = 1\n",
        "X1, y1 = df_to_X_y(X_df, WINDOW_SIZE)\n",
        "#print(X1[0])\n",
        "#print(y1)\n",
        "\n",
        "print('\\nWindow Function done')\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(X_df) * 0.70)\n",
        "test_size = len(X_df) - train_size\n",
        "\n",
        "X_train, y_train = X1[0:train_size], y1[0:train_size]\n",
        "X_test, y_test = X1[train_size:len(X_df)], y1[train_size:len(X_df)]\n",
        "\n",
        "\n",
        "model1 = Sequential() #This is good\n",
        "model1.add(InputLayer((WINDOW_SIZE, 5))) #InputLayer((time_steps, features)\n",
        "model1.add(GRU(64))\n",
        "model1.add(Dense(8, 'relu'))\n",
        "model1.add(Dense(1, 'linear')) #Important\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "'''Compiling the model'''\n",
        "model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.01), metrics=[RootMeanSquaredError()])\n",
        "\n",
        "'''Mapie'''\n",
        "lstm_model=KerasRegressor(build_fn=model1, epochs=10, batch_size=64) #, callbacks=[cp1])\n",
        "#lstm_model.fit(X_train, y_train)\n",
        "#print(\"\\nScikeras model fitted\")\n",
        "\n",
        "mapie_regressor = MapieRegressor(estimator=lstm_model, method='plus')\n",
        "mapie_regressor = mapie_regressor.fit(X_train, y_train)\n",
        "print(\"\\n Mapie model fitted\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Getting Predictions'''\n",
        "train_predictions = mapie_regressor.predict(X_train).flatten() # Flatten gets rid of inner brackets\n",
        "train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train})\n",
        "\n",
        "y_pred, y_pis = mapie_regressor.predict(X_test, alpha=[0.05]) #95% confidence level\n",
        "\n",
        "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Lower Bound': y_pis[:, 0, 0], 'Upper Bound': y_pis[:, 1, 0]})\n",
        "sorted_comparison_df = comparison_df.sort_index()"
      ],
      "metadata": {
        "id": "ifOWQfgmY3lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions_copies = np.reshape(train_predictions, (-1, 1))\n",
        "\n",
        "#train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train})\n",
        "#print(train_results['Train Predictions'])\n",
        "\n",
        "train_predictions = y_scaler.inverse_transform(train_predictions_copies)\n",
        "LowerBound = y_scaler.inverse_transform(np.reshape(y_pis[:, 0, 0], (-1, 1)))\n",
        "UpperBound = y_scaler.inverse_transform(np.reshape(y_pis[:, 1, 0], (-1, 1)))\n",
        "y_pred =  y_scaler.inverse_transform(np.reshape(y_pred, (-1, 1)))\n",
        "y_test =  y_scaler.inverse_transform(np.reshape(y_test, (-1, 1)))\n",
        "\n",
        "#comparison_df = pd.DataFrame({'Actual': y_test[:,0], 'Predicted': y_pred, 'Lower Bound': y_pis[:, 0, 0], 'Upper Bound': y_pis[:, 1, 0]})\n",
        "#comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Lower Bound': LowerBound, 'Upper Bound': UpperBound})\n",
        "#sorted_comparison_df = comparison_df.sort_index()\n",
        "\n",
        "train_index = pd.DataFrame(data=train_predictions).index\n",
        "test_index = pd.DataFrame(data=y_test).index\n",
        "\n",
        "'''Find the maximum index from the training set'''\n",
        "max_train_index = max(train_index)\n",
        "\n",
        "'''Shift the indexes for validation and test sets'''\n",
        "test_index_shifted = [index + max_train_index + 1 for index in test_index]"
      ],
      "metadata": {
        "id": "PCGmDMJ1YzSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_index = list(train_results.index)\n",
        "test_index = sorted_comparison_df.index\n",
        "\n",
        "# Find the maximum index from the training set\n",
        "max_train_index = max(train_index)\n",
        "\n",
        "# Shift the indexes for validation and test sets\n",
        "test_index_shifted = [index + max_train_index + 1 for index in test_index]"
      ],
      "metadata": {
        "id": "_qLOpaiomLkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Plotting\"\"\"\n",
        "\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"VCC (1e6 cells/mL)\")\n",
        "\n",
        "\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "plt.fill_between(test_index_shifted, LowerBound[:,0], UpperBound[:,0], color = 'orange', label = 'Prediction bands', alpha = 0.5)\n",
        "\n",
        "#scatter plot of index vs glucose\n",
        "plt.scatter(train_index, actuals[0:train_size], label='Actual values', color='darkred', s=1)\n",
        "plt.scatter(train_index, train_predictions, label='Predictions', color='blue', s=1)\n",
        "\n",
        "plt.scatter(test_index_shifted, actuals[train_size+1:len(X_df)], color='darkred', s=1)\n",
        "plt.scatter(test_index_shifted, y_pred[:,0], color = 'blue', s=1)\n",
        "\n",
        "\n",
        "legend = plt.legend()\n",
        "legend.legend_handles[0]._sizes = [50]\n",
        "legend.legend_handles[1]._sizes = [30]\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error,  r2_score, mean_absolute_error\n",
        "\n",
        "R2 = r2_score(y_test, y_pred)\n",
        "MSE = mean_squared_error(y_test, y_pred)\n",
        "print('\\nR2 Score: ', R2)\n",
        "print('\\nMSE: ', MSE)"
      ],
      "metadata": {
        "id": "qp-WV7WsVxgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating actuals\n",
        "actuals_concat = actuals[train_size+1:len(X_df)]\n",
        "\n",
        "# Calculating (Upperbound - Lowerbound)/actuals\n",
        "cp_metric = ((UpperBound[:,0] - LowerBound[:,0]) / actuals_concat)*100\n",
        "\n",
        "# Outputting minimum, maximum, and mean of the calculation\n",
        "cp_metric_min = np.min(cp_metric)\n",
        "cp_metric_max = np.max(cp_metric)\n",
        "cp_metric_mean = np.mean(cp_metric)\n",
        "\n",
        "print(\"Minimum of the calculation:\", round(cp_metric_min,3))\n",
        "print(\"Maximum of the calculation:\", round(cp_metric_max,3))\n",
        "print(\"Mean of the calculation:\", round(cp_metric_mean,3))"
      ],
      "metadata": {
        "id": "Vmwu4d0fiQkK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}